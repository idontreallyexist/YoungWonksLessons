{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c29e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f75b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tfds.load('ag_news_subset', split='train', shuffle_files=True, download=False)\n",
    "text=tfds.as_dataframe(df.take(10000))['title'].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fd2668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ddd4062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "423b99ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[49, 50, 51, 52, 53, 54, 55], [72, 73, 74]]>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)\n",
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0568c242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "419fceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()\n",
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f221319",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "seq_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fef4572a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'0' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' '\n",
      " b' ' b' ' b'b' b\"'\" b'A' b'M' b'D' b' ' b'D' b'e' b'b' b'u' b't' b's'\n",
      " b' ' b'D' b'u' b'a' b'l' b'-' b'C' b'o' b'r' b'e' b' ' b'O' b'p' b't'\n",
      " b'e' b'r' b'o' b'n' b' ' b'P' b'r' b'o' b'c' b'e' b's' b's' b'o' b'r'\n",
      " b\"'\" b'\\n' b'1' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' '\n",
      " b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b'b' b'[UNK]' b'W' b'o' b'o' b'd'\n",
      " b\"'\" b's' b' ' b'S' b'u' b's' b'p' b'e' b'n' b's' b'i' b'o' b'n' b' '\n",
      " b'U' b'p' b'h'], shape=(101,), dtype=string)\n",
      "b\"0               b'AMD Debuts Dual-Core Opteron Processor'\\n1                   b[UNK]Wood's Suspension Uph\"\n",
      "b\"eld [UNK]Reuters[UNK][UNK]\\n2          b'Bush reform may have blue states seeing red'\\n3                    b[UNK]'Halt\"\n",
      "b\" science decline in schools'[UNK]\\n4                              b'Gerrard leaves practice'\\n5            \"\n",
      "b\"b'Sony Banking on MGM Deal to Boost Profits'\\n6              b'Giant pandas in China reserve get Wi-Fi\"\n",
      "b\"'\\n7            b'Low turnout for Lithuania [UNK]39;s elections'\\n8         b'Witness says CIA oversaw abus\"\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq))\n",
    "for seq in sequences.take(5):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f40de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "290637af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b\"0               b'AMD Debuts Dual-Core Opteron Processor'\\n1                   b[UNK]Wood's Suspension Up\"\n",
      "Target: b\"               b'AMD Debuts Dual-Core Opteron Processor'\\n1                   b[UNK]Wood's Suspension Uph\"\n"
     ]
    }
   ],
   "source": [
    "split_input_target(list(\"Tensorflow\"))\n",
    "dataset = sequences.map(split_input_target)\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "893f1dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2534b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3432fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable(package='my_package')\n",
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units, **kwargs):\n",
    "    super().__init__()\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "    self.vocab_size = vocab_size\n",
    "    self.embedding_dim = embedding_dim\n",
    "    self.rnn_units = rnn_units\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(tf.shape(x)[0])\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x\n",
    "  \n",
    "  def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"embedding_dim\": self.embedding_dim,\n",
    "            \"rnn_units\": self.rnn_units,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(cls,config):\n",
    "    return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b560e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66952ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[53 49 60 ... 67  2 71]\n",
      " [66 73  2 ... 57 60 57]\n",
      " [ 2  2  2 ...  2  2  2]\n",
      " ...\n",
      " [50 60 63 ...  0  0  4]\n",
      " [60  2 67 ...  2  2  2]\n",
      " [53 67  2 ... 56 49 67]], shape=(64, 100), dtype=int64)\n",
      "(64, 100, 75) # (batch_size, sequence_length, vocab_size)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_model_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"my_model_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>))                 │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">76,875</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │        \u001b[38;5;34m19,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ ((\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;34m64\u001b[0m, │     \u001b[38;5;34m3,938,304\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m1024\u001b[0m))                 │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m75\u001b[0m)          │        \u001b[38;5;34m76,875\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,034,379</span> (15.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,034,379\u001b[0m (15.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,034,379</span> (15.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,034,379\u001b[0m (15.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    print(input_example_batch)\n",
    "    example_batch_predictions = model(np.array(input_example_batch))\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f310c703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72,  4, 59, 45,  2, 39, 41, 59,  9, 31, 41, 68, 25,  9, 37, 19, 74,\n",
       "       41, 62, 57, 21, 71, 71, 46, 43, 32, 49, 38, 34, 74, 46, 34, 24, 68,\n",
       "       31, 25, 64, 15,  5, 40, 23, 59, 37, 40, 13, 49, 43, 32,  2, 69, 71,\n",
       "       37, 55, 19, 37, 11, 42, 62, 10, 26,  2, 53, 26, 73, 23, 27, 74, 59,\n",
       "       63, 21, 30, 73, 64, 70,  2, 73, 50, 62,  0, 34, 69, 43, 63, 65, 30,\n",
       "       18, 24, 67, 58,  7, 16, 40, 27, 33, 66, 51, 46, 20, 63, 10],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b444a27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b\"eal'\\n472                   b'Video phones act as dating tools'\\n473                          b'This w\"\n",
      "\n",
      "Next Char Predictions:\n",
      " b'x$kW QSk.IStC.O9zSni;wwXUJaPLzXLBtICp5&RAkOR3aUJ uwOg9O1Tn0D eDyAEzko;Hypv ybn[UNK]LuUoqH8Bsj,6REKrcX:o0'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8094c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 75)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.3158183, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)\n",
    "tf.exp(example_batch_mean_loss).numpy()\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c847d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.keras\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b99370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 4s/step - loss: 2.9318\n",
      "Epoch 2/3\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 3s/step - loss: 1.9562\n",
      "Epoch 3/3\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 3s/step - loss: 1.8109\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cbb253df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('News.keras')\n",
    "custom_objects={'my_package':MyModel}\n",
    "with keras.saving.custom_object_scope(custom_objects=custom_objects):\n",
    "  model = tf.keras.models.load_model('News.keras',custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a7be31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable(package='my_package2')\n",
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0, **kwargs):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states\n",
    "\n",
    "  def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"model\": self.model,\n",
    "            \"chars_from_ids\": self.chars_from_ids,\n",
    "            \"ids_from_chars\": self.ids_from_chars,\n",
    "            \"temperature\": self.temperature,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(cls, config):\n",
    "        model = keras.saving.deserialize_keras_object(config.pop(\"model\"))\n",
    "        chars_from_ids = keras.saving.deserialize_keras_object(config.pop(\"chars_from_ids\"))\n",
    "        ids_from_chars = keras.saving.deserialize_keras_object(config.pop(\"ids_from_chars\"))\n",
    "        return cls(model=model,\n",
    "                   chars_from_ids=chars_from_ids,\n",
    "                   ids_from_chars=ids_from_chars,\n",
    "                   **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10ea8829",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93172bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaking:  rivald'\n",
      "9800             b'Wormment to Masen Ruthink palligyid'\n",
      "9396      b'END Cotress Bring interive tramon !heroky Dill Fore Pebuld'\n",
      "8096    b'Atmrepbati Worries HMO Flard Daping Hacn: Ch...\n",
      "2808    b'Jupst: Ite near Nexpen Hudea-Qwuel 19090  bma...\n",
      "9788        b'Thed Alpantining Acrains Eets Stry Shiant'\n",
      "9000    b'Al-Mow-2 Gows C-Reputs to Ferms Telion Carne NAP'\n",
      "6762                     b'Opeca tarkel Hail Minge'\n",
      "6031           b'Themmates Tord her agonved acreaded'\n",
      "8533              b'Ning-Chart: Fele Couthto brofind '3904...\n",
      "7441       b'Itto Contrough to Revor T- Clage Studs no Furri...\n",
      "7882                            b'Sporks hote tree Toll'\n",
      "9281    b'UE Bun Inter Toll-in pendictres Revail Priffe...\n",
      "9977              b'Ind Couble Polmbers Nibuter Enghan'\n",
      "9208    b'Signof wamns 1- Ryofger Plana Ats Oullys'\n",
      "9674          b'Suutch Off Fitinel Cap Oud The FB'\n",
      "9804                     b'Fy Inderst 3- JuyDr: Rovitiat'\n",
      "5912          b'Stowy nele ward shream fives in Walis' joul did \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 3.5283257961273193\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['Breaking:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d419dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b\"Breaking:\\n7855         b'Atchebs serke tovedmires mosoft ain OG..\\n9512                                      b'US Pellian Chunce Sear'\\n9385    b'AP to AC now shurmutixht offerity Wunte...\\n4746                b'Lay Extle Fill-ked Toll 2- -GAO Op'\\n8991          b'Sonchede waln soffout sundurigntepters quic...\\n9000                b'Hustory Nex Wound Voorts stops insicust'\\n9780                b'EDM State wivit up Yorse rope'\\n9462    b'Os in Iraq 11 Py UNLoSkide to Ut Shipex, in Airp Im...\\n6603     b'NG an Phangel Revelled    360 Ammi...\\n8973                      b'Puecit EPDARDC'\\n9695                       b'Eunta apenve ista erderterd pone'\\n6042     b'EUrlurereakicy jeartad fur k ned thith oft costed 9...\\n8690    b'AK Hegalan Qulical Sceltwor-te Pureyty Abaly'\\n9984     b'Grown lead for talks  nonted blomb fromted bestack?'\\n9355               b'New gnofit, Dallud for Shirm on Upp'\\n9926    b'UR wind shaigh Eanouncon wititing of Echive Dea...\\n9110    b'Cauma out Yeark Om to minseace disismont i...\\n809\"\n",
      " b\"Sports:\\n7785                                 b'Moushs to Baza Atsoftern'\\n2830                       b'US akalls Tembwall oveur'\\n9995                    b'Bise Bock Surmy Sumplise'\\n8978    b'Bigolosp gless officts resopere Nut to Heems'\\n9835                      b'1900, Iblead Gutrimal'\\n978                     b'USster eds Arger Wirling'\\n9013                 b'Pooxt Sve Eut Ble Lave Thel-mocel'\\n9544                     b'Panallis ampro on Wack in Shomp'\\n8412                      b'Migan Bald Forbs, IR tours'\\n9920     b'Gater on Wineipants Quece Ne Ovect, Wold by Avputo mig ...\\n9001    b'UBg Pan to speliban as at U.S. Wish Sk...\\n8013                 b'Inar Plice' Parkles Neowly wame'\\n9943    b'It Rouet Sornui Aysaict cam potesticl'\\n8970    b'Exto Co Deiner Noa dott limerute ...\\n1387                       b'Tho ald thung of M19m pill'\\n9494                           b'Singendoution his'\\n920               b'Op in Back striughs to het fo' Matchiny'\\n8987           b'OpTlam Mallik: Han Hox Aud Dourts\"\n",
      " b\"Technology: Gake Up, Ctameting'\\n986    b'Winean wands state astaeleriomer coilding beem...\\n7162                        b'Dicloyshbill Diviams kame'\\n9968           b'ECDm Butk Clopiction trate Seathla'\\n9972    b'S.Sote Vockls Cuofer Will wive hoteroligi....\\n8488              b'Stall Clesten Precitine Now O4 Pelay Co.S'\\n9684    b'Bould decket Houndignan explaming treetions on Prebel ...\\n99g7              b'Sculith dognen in dolicore Xvin'\\n9241              b'Wat loloumnert foll for Nefper'\\n9889         b'Illendaip Intrablerg experting plose ...\\n9511           b'Hulloud?: MUN snop tlikis Eus'\\n765    b'Nut ti elvers, in remairsun: erowatie to Klinking...\\n5514    b'Rowentary from almon Tugzet Buald Chinmestll Call...\\n8197    b'Indenting Redoig Net Udd Brazes Tid Pares Cory'\\n7085    b'Bida basclanom wouding bibly dipp shillited post it...\\n1188                   b'Earonaigs op Indupans of'\\n947          b'Clandieventinile 4 Palling forestroud'\\n7496    b'Ecogleraker Cancel loads of divitht winch of ...\\n96\"\n",
      " b\"Politics:\\n7988    b'Plostlonk Halmat 1 D, BT iffackey ....\\n3667    b'Pass, puract Exarine Heckst BA Pis But'\\n9582       b'Fol uphicenidiles, courct quiewings Canreat'\\n9817    b'UPNARx romend kimitoill-for on Cane Catades on T...\\n9063             b'Ou-complits erasifixy thimi...9690    b'Beshirile Prysion SEC mill Gaunnshins Givions'\\n9380           b'New All edunise Molialoft TiPR of Wole Acfor Argcot'\\n8446             b'Buscien blooke caited cleamer in Muneit Wan fi...\\n9264              b'Mitracloost Cricads mabe lossignt Irreat'\\n9790                                 b'ALaig Pich Hoult'\\n7746                      b'Y659, Inetwart Qux Wol Milldy Sare'\\n8947                  b'SJ dive und tagh offer ofter'\\n889              b'USM indicatser tye the Donshal PRecra'\\n9631                        b'IUS peebies lamb'\\n9318                       b'Mejoricy necked 80zoll in to scom'\\n9800                                        b'ARL YRCC UpI'\\n796                         b'Uciteate eirs conkies'\\n963           b\"], shape=(4,), dtype=string) \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 2.6986024379730225\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['Breaking:', 'Sports:', 'Technology:', 'Politics:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0a1af9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OneStep' object has no attribute 'save_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mone_step_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_model\u001b[49m(\u001b[33m'\u001b[39m\u001b[33mNewsOneStep.keras\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m custom_objects={\u001b[33m'\u001b[39m\u001b[33mmy_package\u001b[39m\u001b[33m'\u001b[39m:MyModel,\u001b[33m'\u001b[39m\u001b[33mmy_package2\u001b[39m\u001b[33m'\u001b[39m:OneStep}\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m keras.saving.custom_object_scope(custom_objects=custom_objects):\n",
      "\u001b[31mAttributeError\u001b[39m: 'OneStep' object has no attribute 'save_model'"
     ]
    }
   ],
   "source": [
    "one_step_model.save('NewsOneStep.keras')\n",
    "custom_objects={'my_package':MyModel,'my_package2':OneStep}\n",
    "with keras.saving.custom_object_scope(custom_objects=custom_objects):\n",
    "  one_step_reloaded = tf.keras.models.load_model('NewsOneStep.keras',custom_objects=custom_objects)\n",
    "\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(100):\n",
    "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
